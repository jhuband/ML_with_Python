{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Make sure that your are in the right directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-----Assumes you are running in /scratch-----##\n",
    "import os\n",
    "os.chdir(\"/scratch/\"+os.getenv(\"USER\")+\"/ML_with_Python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Keras Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers \n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_file = 'Data/cancer_data.csv'\n",
    "target_file = 'Data/cancer_target.csv'\n",
    "cancer_data=np.loadtxt(data_file,dtype=float,delimiter=',')\n",
    "cancer_target=np.loadtxt(target_file, dtype=float, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "test_size = 0.30\n",
    "seed = 7\n",
    "train_data, test_data, train_target, test_target = model_selection.train_test_split(cancer_data,\n",
    "        cancer_target, test_size=test_size, \n",
    "        random_state=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data \n",
    "scaler.fit(train_data)\n",
    "\n",
    "# Now apply the transformations to the data: \n",
    "x_train = scaler.transform(train_data) \n",
    "x_test = scaler.transform(test_data)\n",
    "\n",
    "# Convert the classes to ‘one-hot’ vector \n",
    "y_train = to_categorical(train_target, num_classes=2) \n",
    "y_test = to_categorical(test_target, num_classes=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    from tensorflow.keras.models import Sequential \n",
    "    from tensorflow.keras.layers import Dense, Dropout \n",
    "    from tensorflow.keras.optimizers import SGD\n",
    "    model = keras.Sequential([ \n",
    "       layers.Dense(30, activation=\"relu\"), \n",
    "       layers.Dropout(0.5),\n",
    "       layers.Dense(60, activation=\"relu\"), \n",
    "       layers.Dropout(0.5),\n",
    "       layers.Dense(2, activation=\"softmax\") \n",
    "    ])\n",
    "    model.compile(optimizer=\"rmsprop\", \n",
    "              loss=\"binary_crossentropy\",\n",
    "             \n",
    "                  metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return(model)\n",
    "    \n",
    "model = define_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size = int(.8*x_train.shape[0])\n",
    "num_epochs = 20\n",
    "\n",
    "model.fit(x_train, y_train, epochs=num_epochs, batch_size=b_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the Model to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(model.predict(x_test), axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=b_size) \n",
    "print('\\nAccuracy:  %.3f' % score[1])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "print(confusion_matrix(test_target, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.4.1/Keras Py3.7",
   "language": "python",
   "name": "tensorflow-2.4.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
